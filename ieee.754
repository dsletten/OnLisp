Double-precision float stores significand in 52 bits with implied H.O. bit of 1. (Sign/exponent take 12 bits)
The <SIGNIFICAND> (primary value) returned by INTEGER-DECODE-FLOAT contains this implicit H.O. bit.
For example:
pi => 3.141592653589793
(format t "~B~%" (integer-decode-float pi)) => 11001001000011111101101010100010001000010110100011000
(format t "~X~%" (integer-decode-float pi)) => 1921FB54442D18

Compare:
http://binaryconvert.com/result_double.html
3.141592653589793 => 0x400921FB54442D18

Sign Exponent      Significand
0    10000000000   1001001000011111101101010100010001000010110100011000
     400           921FB54442D18

Lisp:     11001001000011111101101010100010001000010110100011000
          1   9   2   1   F   B   5   4   4   4   2   D   1   8
IEEE-754:  1001001000011111101101010100010001000010110100011000
              9   2   1   F   B   5   4   4   4   2   D   1   8
-----------------------------------------------------------------
The exponent returned by INTEGER-DECODE-FLOAT differs from the IEEE-754 representation in 2 ways:
- The IEEE exponent is an "excess" value shifted by 1023, 127 for double-precision, single-precision respectively.
- The Lisp value is an integer, which scales the significand by 52, 23 places, respectively.

IEEE:
Float.MAX_VALUE
$25 ==> 3.4028235E38

Integer.toHexString(Float.floatToRawIntBits(Float.MAX_VALUE))
$30 ==> "7f7fffff"
Sign Exponent      Significand
0    11111110      11111111111111111111111
     FE            7FFFFF
     254           8388607

Exponent 254 -> (254 - 127) = 127

Thus, MOST-POSITIVE-SINGLE-FLOAT = ([1].11111111111111111111111)₂ X 2¹²⁷

Lisp:
most-positive-single-float => 3.4028235e38
(integer-decode-float most-positive-single-float)
16777215
104
1

7FFFFF -> FFFFFF (Implied bit) = 16777215
Significand: 1.11111111111111111111111 -> 111111111111111111111111 by shifting binary point by 23 places.

Thus, given IEEE exponent 254:
(254 - 127) - 23 = 104
-----------------------------------------------------------------
IEEE:
Double.MAX_VALUE
$32 ==> 1.7976931348623157E308

Long.toHexString(Double.doubleToRawLongBits(Double.MAX_VALUE))
$31 ==> "7fefffffffffffff"
Sign Exponent      Significand
0    11111111110   1111111111111111111111111111111111111111111111111111
     7FE           FFFFFFFFFFFFF
     2046          4503599627370495

Exponent 2046 -> (2046 - 1023) = 1023

Thus, MOST-POSITIVE-DOUBLE-FLOAT = ([1].1111111111111111111111111111111111111111111111111111)₂ X 2¹⁰²³

Lisp:
most-positive-double-float => 1.7976931348623157d308
(integer-decode-float most-positive-double-float)
9007199254740991
971
1

FFFFFFFFFFFFF -> 1FFFFFFFFFFFFF (Implied bit) = 9007199254740991
Significand: 1.1111111111111111111111111111111111111111111111111111 -> 11111111111111111111111111111111111111111111111111111 by shifting binary point by 52 places.

Thus, given IEEE exponent 2046:
(2046 - 1023) - 52 = 971
-----------------------------------------------------------------
* (= (+ 0.1d0) (* 1 0.1d0))
T
* (= (+ 0.1d0 0.1d0) (* 2 0.1d0))
T
* (= (+ 0.1d0 0.1d0 0.1d0) (* 3 0.1d0))
T
* (= (+ 0.1d0 0.1d0 0.1d0 0.1d0) (* 4 0.1d0))
T
* (= (+ 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0) (* 5 0.1d0))
T
* (= (+ 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0) (* 6 0.1d0))
NIL


* (rational (+ 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0))
5404319552844595/9007199254740992
* (rational  (* 6 0.1d0))
1351079888211149/2251799813685248
* (- * **)
1/9007199254740992

5404319552844595   1351079888211149   5404319552844596
---------------- < ---------------- = ----------------
9007199254740992   2251799813685248   9007199254740992



3 potentially separate values:
- 0.6d0
- (* 6 0.1d0)
- (+ 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0)


* (integer-decode-float (+ 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0))
5404319552844595
-53
1
* (integer-decode-float  (* 6 0.1d0))
5404319552844596
-53
1
* (integer-decode-float 0.6d0)
5404319552844595
-53
1


* (integer-decode-float (+ 0.1d0 0.1d0 0.1d0 0.1d0 0.1d0))
4503599627370496
-53
1
* (integer-decode-float (+ 0.1d0 0.1d0 0.1d0 0.1d0))
7205759403792794
-54
1
* (integer-decode-float (+ 0.1d0 0.1d0 0.1d0))
5404319552844596
-54
1
* (integer-decode-float (+ 0.1d0 0.1d0))
7205759403792794
-55
1
* (integer-decode-float 0.1d0)
7205759403792794
-56
1

jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.1))
$8 ==> "11111110111001100110011001100110011001100110011001100110011010"


jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.2))
$9 ==> "11111111001001100110011001100110011001100110011001100110011010"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.1 + 0.1))
$10 ==> "11111111001001100110011001100110011001100110011001100110011010"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(2 * 0.1))
$23 ==> "11111111001001100110011001100110011001100110011001100110011010"


jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.3))
$11 ==> "11111111010011001100110011001100110011001100110011001100110011"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.1 + 0.1 + 0.1))
$12 ==> "11111111010011001100110011001100110011001100110011001100110100"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(3 * 0.1))
$13 ==> "11111111010011001100110011001100110011001100110011001100110100"


jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.4))
$14 ==> "11111111011001100110011001100110011001100110011001100110011010"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.1 + 0.1 + 0.1 + 0.1))
$15 ==> "11111111011001100110011001100110011001100110011001100110011010"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(4 * 0.1))
$16 ==> "11111111011001100110011001100110011001100110011001100110011010"


jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.5))
$17 ==> "11111111100000000000000000000000000000000000000000000000000000"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.1 + 0.1 + 0.1 + 0.1 + 0.1))
$18 ==> "11111111100000000000000000000000000000000000000000000000000000"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(5 * 0.1))
$19 ==> "11111111100000000000000000000000000000000000000000000000000000"


jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.6))
$20 ==> "11111111100011001100110011001100110011001100110011001100110011"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1))
$21 ==> "11111111100011001100110011001100110011001100110011001100110011"

jshell> Long.toBinaryString(Double.doubleToRawLongBits(6 * 0.1))
$22 ==> "11111111100011001100110011001100110011001100110011001100110100"



0.1
Long.toBinaryString(Double.doubleToRawLongBits(0.1))
==> "11111110111001100110011001100110011001100110011001100110011010"
Actually:
  11111110111001100110011001100110011001100110011001100110011010
0011111110111001100110011001100110011001100110011001100110011010
0 01111111011 1.1001100110011001100110011001100110011001100110011010


1.1001100110011001100110011001100110011001100110011010 X 2^-4
(/ 1 16d0) => 0.0625
11.001100110011001100110011001100110011001100110011010 X 2^-5
(/ 3 32d0) => 0.09375
110.01100110011001100110011001100110011001100110011010 X 2^-6
(/ 6 64d0) => 0.09375
1100.1100110011001100110011001100110011001100110011010 X 2^-7
(/ 12 128d0) => 0.09375
11001.100110011001100110011001100110011001100110011010 X 2^-8
(/ 25 256d0) => 0.09765625
110011.00110011001100110011001100110011001100110011010 X 2^-9
(/ 51 512d0) => 0.099609375


                                                            Expt
  1.1001100110011001100110011001100110011001100110011010    -4
+ 1.1001100110011001100110011001100110011001100110011010    -4
--------------------------------------------------------
 11.0011001100110011001100110011001100110011001100110100    -4
  1.1001100110011001100110011001100110011001100110011010(0) -3

0.2 (literal/sum/product)
0 01111111100 1.1001100110011001100110011001100110011001100110011010
0 01111111100 1.1001100110011001100110011001100110011001100110011010
0 01111111100 1.1001100110011001100110011001100110011001100110011010


  1.1001100110011001100110011001100110011001100110011010    -4
  1.1001100110011001100110011001100110011001100110011010    -4
+ 1.1001100110011001100110011001100110011001100110011010    -4
--------------------------------------------------------
 11.0011001100110011001100110011001100110011001100110100    -4
  1.1001100110011001100110011001100110011001100110011010    -4
--------------------------------------------------------
100.1100110011001100110011001100110011001100110011001110    -4
  1.0011001100110011001100110011001100110011001100110011(10)-2

0.3
0 01111111101 1.0011001100110011001100110011001100110011001100110011 <- Truncated
0 01111111101 1.0011001100110011001100110011001100110011001100110100 <- Rounded
0 01111111101 1.0011001100110011001100110011001100110011001100110100


0.4
0 01111111101 1.1001100110011001100110011001100110011001100110011010
0 01111111101 1.1001100110011001100110011001100110011001100110011010
0 01111111101 1.1001100110011001100110011001100110011001100110011010


0.5
0 01111111110 1.0000000000000000000000000000000000000000000000000000
0 01111111110 1.0000000000000000000000000000000000000000000000000000
0 01111111110 1.0000000000000000000000000000000000000000000000000000


   1.1001100110011001100110011001100110011001100110011010      -4

   1.1001100110011001100110011001100110011001100110011010      -4
   1.1001100110011001100110011001100110011001100110011010      -4
   1.1001100110011001100110011001100110011001100110011010      -4
   1.1001100110011001100110011001100110011001100110011010      -4
+  1.1001100110011001100110011001100110011001100110011010      -4
---------------------------------------------------------
1000.0000000000000000000000000000000000000000000000000         -4    (0.5)
+  1.1001100110011001100110011001100110011001100110011010      -4
---------------------------------------------------------
1001.1001100110011001100110011001100110011001100110011010      -4
   1.0011001100110011001100110011001100110011001100110011(010) -1

0.6
0 01111111110 1.0011001100110011001100110011001100110011001100110011 <- Truncated
0 01111111110 1.0011001100110011001100110011001100110011001100110011 <- Truncated
0 01111111110 1.0011001100110011001100110011001100110011001100110100 <- Rounded



0.6 = 2 * 0.3

* (= (* 2 0.3d0) (* 6 0.1d0))
NIL
* (integer-decode-float (* 2 0.3d0))
5404319552844595
-53
1
* (integer-decode-float (* 6 0.1d0))
5404319552844596
-53
1

0 01111111101 1.0011001100110011001100110011001100110011001100110011 0.3d0
0 01111111110 1.0011001100110011001100110011001100110011001100110011 (* 2 0.3d0)
0 01111111110 1.0011001100110011001100110011001100110011001100110100 (* 6 0.1d0)
-----------------------------------------------------------------
Infinity/NaN all exponent bits 1.
Infinity all significand bits 0:
Long.toHexString(Double.doubleToRawLongBits(Double.POSITIVE_INFINITY))
$33 ==> "7ff0000000000000"

Long.toHexString(Double.doubleToRawLongBits(Double.NEGATIVE_INFINITY))
$34 ==> "fff0000000000000"

NaN not all significand bits 0:
Long.toHexString(Double.doubleToRawLongBits(Double.NaN))
$35 ==> "7ff8000000000000"

long l = Double.doubleToRawLongBits(Double.NaN) 
l ==> 9221120237041090560

l++
l ==> 9221120237041090561

Double.longBitsToDouble(l)
$39 ==> NaN




Clojure notes:
Clojure has special numeric values for positive and negative infinity and not-a-number (NaN) to signal certain exceptional results:
(/ 1.0 0.0) => ##Inf
(/ -1.0 0.0) => ##-Inf
(/ 0.0 0.0) => ##NaN
But did you ever wonder what those values really were?
First, let's examine a typical double-precision float, e.g., pi:
Math/PI => 3.141592653589793
(Long/toHexString (Double/doubleToRawLongBits Math/PI)) => "400921fb54442d18"
This shows the machine representation of an IEEE-754 double.
Sign: 1 bit (0 = positive, 1 = negative)
Exponent: 11 bits ("1023 excess". Subtract 1023 to get true exponent)
Significand: 52 bits (Plus a 53rd "hidden" bit. The leading bit is always assumed to be 1)
Sign Exponent    Significand
0    10000000000 1001001000011111101101010100010001000010110100011000
Here, the exponent is 0b10000000000 = 1024.
Minus the "1023 excess" 1024 - 1023 = 1
Thus pi = 1.1001001000011111101101010100010001000010110100011000 X 2^1
Now the special values for infinity and NaN have a particular pattern. All of the exponent bits are 1.
For infinity, all of the significand bits are 0:
(Long/toHexString (Double/doubleToRawLongBits Double/POSITIVE_INFINITY))
"7ff0000000000000"
0 11111111111 0000000000000000000000000000000000000000000000000000

(Long/toHexString (Double/doubleToRawLongBits Double/NEGATIVE_INFINITY))
"fff0000000000000"
1 11111111111 0000000000000000000000000000000000000000000000000000
And for NaN, not all of the significand bits are 0:
(Long/toHexString (Double/doubleToRawLongBits Double/NaN))
"7ff8000000000000"
0 11111111111 1000000000000000000000000000000000000000000000000000
Any number that has this pattern is a NaN value:
(Double/doubleToRawLongBits Double/NaN) => 9221120237041090560
(inc (Double/doubleToRawLongBits Double/NaN)) => 9221120237041090561
(Double/longBitsToDouble (inc (Double/doubleToRawLongBits Double/NaN))) => ##NaN
(Long/toHexString (Double/doubleToRawLongBits *1)) => "7ff8000000000001"
So evidently there are 2^52 - 1 possible NaN values!

